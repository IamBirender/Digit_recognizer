{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>MNIST - Multiclass Classification With CNN (Keras)</center>\n",
    "<center><img src=\"files/keras-logo.png\"></center>\n",
    "\n",
    "IN this notebook, we will build Multi-class classification for the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) using Convolution Neural Networks (CNN). \n",
    "\n",
    "The MNIST dataset is an image dataset of handwritten digits. It has has 60,000 training images and 10,000 test images, each of which are grayscale 28 x 28 sized images.It is a good beginner's dataset to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting.\n",
    "\n",
    "In this notebook, we will develop a Convolutional Neural Network using the Keras library to classify these handwritten images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports & tweaks\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys, time\n",
    "\n",
    "plt.style.use('seaborn-colorblind')\n",
    "plt.rcParams['figure.figsize'] = (8,6)\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_context('talk')\n",
    "sns.set_style({'font.sans-serif':['Verdana','Arial','Calibri','DejaVu Sans']})\n",
    "%matplotlib inline\n",
    "\n",
    "# NOTE: Always use a seed for random number generators, so you get same results across runs\n",
    "# you can use any number as the seed \n",
    "seed = 123\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Images\n",
    "\n",
    "While you can download the dataset from [this link](http://yann.lecun.com/exdb/mnist/), the Keras library already includes these digits in the `keras.datasets` module. We will load the digits from this library to save pre-processing time. I am going to use the `karas.datasets.mnist.load_data()` call. This function conveniently returns two tuples of images & labels - one for the training dataset and the other for test dataset. \n",
    "\n",
    "However:\n",
    "* The images are not _shaped_ correctly - images tuples are shaped as `(num_samples, image_height, image_width)`, whereas we need them to be shaped as `(num_samples, image_height, image_width, num_channels)`, which is input shape of our images to the CNN.You can feed the images in any shape (e.g. `(num_samples, image_height * image_width)`, so long as you are consistent across the training & test sets!)\n",
    "* The images data needs to be converted to `float32` and scaled (we will opt to scale values between 0.0 and 1.0)\n",
    "* While the label tuples are shaped correctly as `(num_samples, class)`, we need to _one-hot-encode_ the labels, so our CNN output layer can correctly process it. For 10 output class, each label should be encoded into an array of shape `(1, 10)` with all zeros except at the index of the digit (e.g. 3 becomes `[0 0 0 1 0 0 0 0 0 0]` and so on).\n",
    "\n",
    "We will handle all these transformations as in our pre-processing code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets.mnist import load_data\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_digits, train_labels), (test_digits, test_labels) = load_data()\n",
    "train_digits.shape, train_labels.shape, test_digits.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we have 60,000 images in the training set & 10,000 images in the test set. Let's randomly pick `14 images` from the `train_digits` set and see how they look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_14 = np.random.randint(0, train_digits.shape[0],14)\n",
    "sample_digits = train_digits[rand_14]\n",
    "sample_labels = train_labels[rand_14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 14 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_rows, num_cols = 2, 7\n",
    "f, ax = plt.subplots(num_rows, num_cols, figsize=(12,5),gridspec_kw={'wspace':0.03, 'hspace':0.01}, squeeze=True)\n",
    "for r in range(num_rows):\n",
    "    for c in range(num_cols):\n",
    "        image_index = r * 7 + c\n",
    "        ax[r,c].axis(\"off\")\n",
    "        ax[r,c].imshow(sample_digits[image_index], cmap='gray')\n",
    "        ax[r,c].set_title('No. %d' % sample_labels[image_index])\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will prepare the data for consumption by our Convolutional Neural Network, which we will create later. Recall that this involves:\n",
    "* **Reshaping the images data** to a tensor of shape `(num_samples, image_height, image_width, num_channels)` - for our 28x28 grayscale images, this would be `(num_samples, 28, 28, 1)`, where `num_samples = 60,000` for train dataset and `num_samples = 10,000` for test dataset. An `np.reshape(...)` call will help us do just that.\n",
    "* **Re-scaling the images data** to a values between 0.0 and 255.0\n",
    "* **One-hot-encode** the labels - Keras provides a `to_categorical()` function in it's `utils` module, which we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some variables to help with pre-processing...\n",
    "image_height, image_width = train_digits.shape[1], train_digits.shape[2]\n",
    "num_channels = 1  # we have grayscale images\n",
    "input_shape = image_height * image_width * num_channels\n",
    "image_height, image_width, num_channels, input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (10000, 28, 28, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re-shape the images data\n",
    "train_data = np.reshape(train_digits,(train_digits.shape[0], image_height, image_width, num_channels))\n",
    "test_data = np.reshape(test_digits,(test_digits.shape[0],image_height, image_width, num_channels))\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-scale the images data to values between (0.0 and 255.0] (i.e. 0.0 <= value < 255.0)\n",
    "train_data = train_data.astype('float32') / 255.\n",
    "test_data = test_data.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 10), (10000, 10))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot-encode the labels\n",
    "num_classes = 10\n",
    "train_labels_cat = to_categorical(train_labels,num_classes)\n",
    "test_labels_cat = to_categorical(test_labels,num_classes)\n",
    "train_labels_cat.shape, test_labels_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (60000, 10), (10000, 28, 28, 1), (10000, 10))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, train_labels_cat.shape, test_data.shape, test_labels_cat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will split the _training set_ into _training & cross-validation_ sets. We will _train_ my model _on the training set_ & _evaluate performance on validation set_ during the training process (i.e. cross-validate). I will _set aside the test-set_ for a final test run, after I am satisfied with my metrics from training. This way, I always have some data that the model has never seen. This helps me avoid overfitting to some extent. We will set aside 10% of the training_set as the validation set.<br/>\n",
    "Of course, to ensure randomness in selecting the data, we will also shuffle the training set (5 times!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54000, 28, 28, 1),\n",
       " (54000, 10),\n",
       " (6000, 28, 28, 1),\n",
       " (6000, 10),\n",
       " (10000, 28, 28, 1),\n",
       " (10000,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle the training dataset & set aside val_perc % of rows as validation data\n",
    "for _ in range(5): \n",
    "    indexes = np.random.permutation(len(train_data))\n",
    "\n",
    "# randomly sorted!\n",
    "train_data = train_data[indexes]\n",
    "train_labels_cat = train_labels_cat[indexes]\n",
    "\n",
    "# now we will set-aside val_perc% of the train_data/labels as cross-validation sets\n",
    "val_perc = 0.10\n",
    "val_count = int(val_perc * len(train_data))\n",
    "\n",
    "# first pick validation set\n",
    "val_data = train_data[:val_count,:]\n",
    "val_labels_cat = train_labels_cat[:val_count,:]\n",
    "\n",
    "# leave rest in training set\n",
    "train_data2 = train_data[val_count:,:]\n",
    "train_labels_cat2 = train_labels_cat[val_count:,:]\n",
    "\n",
    "train_data2.shape, train_labels_cat2.shape, val_data.shape, val_labels_cat.shape, test_data.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some globals\n",
    "num_features = train_data.shape[1]\n",
    "num_epochs = 5\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a utility function that plots the losses and accuracies for training & validation sets across our epochs\n",
    "def show_plots(history):\n",
    "    \"\"\" Useful function to view plot of loss values & accuracies across the various epochs \"\"\"\n",
    "    loss_vals = history['loss']\n",
    "    val_loss_vals = history['val_loss']\n",
    "    epochs = range(1, len(history['acc'])+1)\n",
    "    \n",
    "    f, ax = plt.subplots(nrows=1,ncols=2,figsize=(16,4))\n",
    "    \n",
    "    # plot losses on ax[0]\n",
    "    ax[0].plot(epochs, loss_vals, color='navy',marker='o', linestyle=' ', label='Training Loss')\n",
    "    ax[0].plot(epochs, val_loss_vals, color='firebrick', marker='*', label='Validation Loss')\n",
    "    ax[0].set_title('Training & Validation Loss')\n",
    "    ax[0].set_xlabel('Epochs')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].legend(loc='best')\n",
    "    ax[0].grid(True)\n",
    "    \n",
    "    # plot accuracies\n",
    "    acc_vals = history['acc']\n",
    "    val_acc_vals = history['val_acc']\n",
    "\n",
    "    ax[1].plot(epochs, acc_vals, color='navy', marker='o', ls=' ', label='Training Accuracy')\n",
    "    ax[1].plot(epochs, val_acc_vals, color='firebrick', marker='*', label='Validation Accuracy')\n",
    "    ax[1].set_title('Training & Validation Accuracy')\n",
    "    ax[1].set_xlabel('Epochs')\n",
    "    ax[1].set_ylabel('Accuracy')\n",
    "    ax[1].legend(loc='best')\n",
    "    ax[1].grid(True)\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # delete locals from heap before exiting\n",
    "    del loss_vals, val_loss_vals, epochs, acc_vals, val_acc_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_time_taken(start_time, end_time):\n",
    "    secs_elapsed = end_time - start_time\n",
    "    \n",
    "    SECS_PER_MIN = 60\n",
    "    SECS_PER_HR  = 60 * SECS_PER_MIN\n",
    "    \n",
    "    hrs_elapsed, secs_elapsed = divmod(secs_elapsed, SECS_PER_HR)\n",
    "    mins_elapsed, secs_elapsed = divmod(secs_elapsed, SECS_PER_MIN)\n",
    "    \n",
    "    if hrs_elapsed > 0:\n",
    "        print('Time taken: %d hrs %d mins %d secs' % (hrs_elapsed, mins_elapsed, secs_elapsed))\n",
    "    elif mins_elapsed > 0:\n",
    "        print('Time taken: %d mins %d secs' % (mins_elapsed, secs_elapsed))\n",
    "    elif secs_elapsed > 1:\n",
    "        print('Time taken: %d secs' % (secs_elapsed))\n",
    "    else:\n",
    "        print('Time taken - less than 1 sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model Development\n",
    "\n",
    "Our Keras model will have the following configuration:\n",
    "* 3 `Conv2d` layers, each with 32, 64 and 64 filters and `relu` activation functions and a `(3,3)` kernel size, and `padding='same'`\n",
    "* We follow each Conv2d layer with a `MaxPooling2d` layer with a `(2,2)` pool size\n",
    "* Finally, we have a `Dense` layer with 512 nodes and `relu` activation.\n",
    "* The output `Dense` layer has 10 nodes (for the 10 digits) and a `softmax` activation function (for a a multi-class classification problem)\n",
    "* We use the `categorical-crossentropy` loss and the `adam` optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    # add Convolutional layers\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same',\n",
    "                     input_shape=(image_height, image_width, num_channels)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))    \n",
    "    model.add(Flatten())\n",
    "    # Densely connected layers\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    # output layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # compile with adam optimizer & categorical_crossentropy loss function\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/joeoperator/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/joeoperator/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1062: calling reduce_prod_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Users/joeoperator/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2550: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               73856     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 130,890.0\n",
      "Trainable params: 130,890.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/joeoperator/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 105s - loss: 0.1765 - acc: 0.9440 - val_loss: 0.0578 - val_acc: 0.9822\n",
      "Epoch 2/15\n",
      " 8960/54000 [===>..........................] - ETA: 82s - loss: 0.0525 - acc: 0.9833"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "history = model.fit(train_data2, train_labels_cat2, epochs=15, batch_size=64,\n",
    "                    validation_data=(val_data, val_labels_cat))\n",
    "end_time = time.time()\n",
    "print_time_taken(start_time, end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** With this CNN, we get a training accuracy of 99.7% (and validation accuracy of 99.3%) - see last line of output above. \n",
    "\n",
    "Next, let us view plots of train & validation accuracies vs epochs and train & validation losses vs epochs. We will use the `show_plots()` helper function coded above which presents these charts in a 1x2 grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_plots(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots suggests that this Keras model is overfitting the training data after 3-4 epochs: \n",
    "* We can see from the top-left plot that the training loss is falling smoothly towards zero, however the test loss falls for some epochs and then rises somewhat after the 4th epoch.\n",
    "* Also in the accuracy plots (top-right), we observe that the training accuracu rises towards 100%, whereas the validation accuracy flattens out after around 4 epochs - at a value around 99%. \n",
    "* This is a typical behavior of an overfitting model. However our validation loss is not significantly lesser than our training loss, indicating that the model is overfitting only slightly.\n",
    "\n",
    "Let us see how our model is performing against test data that it has not _seen_ so far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_data, test_labels_cat, batch_size=batch_size)\n",
    "print('Test loss: %.4f accuracy: %.4f' % (test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** We get a test accuracy of 99.3% with the test data, which is a great metric! Our model is generalizing well (i.e. the accuracy score is good on data that it has not seen before). \n",
    "## Predictions\n",
    "Next, let us run some predictions using this model & test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's predict the outcomes of our model\n",
    "kr_test_pred = model.predict(test_data)\n",
    "# NOTE: each member of kr_test_pred would be a (1,10) array \n",
    "# each index of the array holds the probability that the model thinks it is the digit at that offset\n",
    "# example for digit [??] -> [???]\n",
    "# The index which holds the maximum probability value is the predictioon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view first 20 - both predicted & actual\n",
    "np.argmax(kr_test_pred, axis=1)[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(test_labels_cat,axis=1)[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many mismatches?\n",
    "(np.argmax(kr_test_pred, axis=1) != np.argmax(test_labels_cat,axis=1)).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have around 80 of 10,000 mismatched records in our test data. Not bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save our model\n",
    "model.save('./model_states/keras_mnist.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "* In this workbook we created a CNN with Keras to classify the MNIST digits.\n",
    "* We were able to achieve test accuracy of 99%, though our model was overfitting slightly.\n",
    "\n",
    "# <center> - - END - - </center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
